{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec5ed30",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# MAKI4U Jumpstart Notebook\n",
    "\n",
    "A Notebook for training new BERT models for MAKI4U (former CCAI)\\\n",
    "This is a refactored version of \"bert_train_classifier.ipynb\" from the\n",
    "BAS Jumpstart\\ and is meant as optimization and general clean up of that notebook\\\n",
    "It is possible to use this as notebook or directly as a script\n",
    "\n",
    "\n",
    "This notebook is organized in\n",
    "* [Configuration for Model and Logging](#config)\n",
    "* [Loading Dataset](#dataset)\n",
    "* [Model Definition](#model)\n",
    "* [Train Model](#train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e12900",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b019a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14763025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from IPython import get_ipython\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from transformers.utils import check_min_version\n",
    "import yaml\n",
    "from utils.bert_custom_trainer import TrainerDiceLoss\n",
    "from utils.configuration import (\n",
    "    parse_arguments,\n",
    "    save_config,\n",
    "    yaml_dump_for_notebook,\n",
    "    isnotebook,\n",
    ")\n",
    "from utils.metrics import compute_metrics\n",
    "from utils.BERT import BERT\n",
    "from typing import List, Set, Dict, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daee19be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
    "# check_min_version(\"4.9.0.dev0\")\n",
    "transformers.logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e1503",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic(\"matplotlib\", \"inline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b6452",
   "metadata": {},
   "source": [
    "## Configuration and Logging <a class=\"anchor\" id=\"config\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166506ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra variable for processing big files in BERT\n",
    "# https://github.com/huggingface/datasets/issues/2181\n",
    "block_size_10MB = 10 << 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0dec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isnotebook():\n",
    "    # In a notebook you need to just dump the yaml with the configuration details\n",
    "    args_dict = yaml_dump_for_notebook()\n",
    "    # print(args_dict)\n",
    "else:\n",
    "    # This can only be used if this is run as a script. For notebooks use the yaml.dump and configure the yaml file accordingly\n",
    "    args, device = parse_arguments()\n",
    "    args_dict = args.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d9bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename, filepath = save_config(args_dict)\n",
    "print(filename, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ede34",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f\"{filepath}/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15a45f1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Loading Dataset <a class=\"anchor\" id=\"dataset\"></a>\n",
    "### TODO: Refactor this properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb0ecd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "json_files = str(Path(args_dict[\"data_folder\"]).joinpath(args_dict[\"data_file\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbcbc94",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "json_files_train = [json_files.replace(\".json\", \"\") + \"_train.json\"]\n",
    "json_files_dev = [json_files.replace(\".json\", \"\") + \"_dev.json\"]\n",
    "json_files_test = [json_files.replace(\".json\", \"\") + \"_test.json\"]\n",
    "\n",
    "dataset_train = load_dataset(\n",
    "    \"json\", data_files=json_files_train, chunksize=block_size_10MB\n",
    ")[\"train\"]\n",
    "\n",
    "dataset_dev = load_dataset(\n",
    "    \"json\", data_files=json_files_dev, chunksize=block_size_10MB\n",
    ")[\"train\"]\n",
    "\n",
    "dataset_test = load_dataset(\n",
    "    \"json\", data_files=json_files_test, chunksize=block_size_10MB\n",
    ")[\"train\"]\n",
    "\n",
    "dataset_train = dataset_train.class_encode_column(\"label\")\n",
    "dataset_dev = dataset_dev.class_encode_column(\"label\")\n",
    "dataset_test = dataset_test.class_encode_column(\"label\")\n",
    "\n",
    "assert (\n",
    "    dataset_train.features[\"label\"].names == dataset_test.features[\"label\"].names == dataset_dev.features[\"label\"].names\n",
    "), \"Something went wrong, target_names of train and test should be the same\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fc479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    args_dict[\"checkpoint_tokenizer\"], use_fast=True, model_max_length=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf7b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.map(\n",
    "    lambda x: tokenizer(x['text'], truncation=True), \n",
    "    batched=True\n",
    "    #num_proc=args_dict[\"tokenizer_num_processes\"]\n",
    ")\n",
    "\n",
    "dataset_dev = dataset_dev.map(\n",
    "    lambda x: tokenizer(x['text'], truncation=True), \n",
    "    batched=True\n",
    "    #num_proc=args_dict[\"tokenizer_num_processes\"]\n",
    ")\n",
    "\n",
    "dataset_test = dataset_test.map(\n",
    "    lambda x: tokenizer(x['text'], truncation=True), \n",
    "    batched=True\n",
    "    #num_proc=args_dict[\"tokenizer_num_processes\"]\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ab942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(dataset_train[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b2f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = dataset_train.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7d1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use shuffle to make sure the order of samples is randomized (deterministically)\n",
    "dataset_train = dataset_train.shuffle(seed=args_dict[\"random_seed\"])\n",
    "dataset_dev = dataset_dev.shuffle(seed=args_dict[\"random_seed\"])\n",
    "#ds_train_testvalid = dataset_train.train_test_split(\n",
    "#    test_size=(1 - args_dict[\"split_ratio_train\"])\n",
    "#)\n",
    "\n",
    "dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": dataset_train,\n",
    "        \"valid\": dataset_dev,\n",
    "        \"test\": dataset_test\n",
    "    }\n",
    ")\n",
    "\n",
    "target_names = dataset[\"test\"].features[\"label\"].names\n",
    "\n",
    "if args_dict[\"oversampling\"]:\n",
    "    df_train = dataset[\"train\"].to_pandas()\n",
    "    min_samples = math.ceil(len(df_train) * args_dict[\"oversampling\"])\n",
    "    count_dict = dict(df_train[\"label\"].value_counts())\n",
    "    count_dict = {k: v for k, v in count_dict.items() if v < min_samples}\n",
    "\n",
    "    over_samples = []\n",
    "    for label_id, n_occurance in count_dict.items():\n",
    "        class_samples = df_train[df_train[\"label\"] == label_id]\n",
    "        additional_samples = class_samples.sample(\n",
    "            n=(min_samples - len(class_samples)), replace=True\n",
    "        )\n",
    "        over_samples.append(additional_samples)\n",
    "        print(\n",
    "            f\"\\nAdding {len(additional_samples)} samples for class {target_names[label_id]}\"\n",
    "        )\n",
    "\n",
    "    new_train = pd.concat([df_train, *over_samples])\n",
    "    dataset[\"train\"] = Dataset.from_pandas(new_train)\n",
    "\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].shuffle(seed=args_dict[\"random_seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a719e35",
   "metadata": {},
   "source": [
    "## Model Definition <a class=\"anchor\" id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e73224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class definition was moved to utils for easier mentainance across notebooks\n",
    "model_obj = BERT(\n",
    "    args_dict, num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_class = Trainer\n",
    "if args_dict[\"custom_trainer\"] == \"TrainerDiceLoss\":\n",
    "    trainer_class = TrainerDiceLoss\n",
    "    print(\"USING CUSTOM TRAINER CLASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c2918",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    filename,\n",
    "    evaluation_strategy=args_dict[\"evaluation_strategy\"],\n",
    "    eval_steps=args_dict[\"evaluation_steps\"],\n",
    "    logging_dir=filepath,\n",
    "    lr_scheduler_type=args_dict[\"lr_scheduler_type\"],\n",
    "    learning_rate=float(args_dict[\"lr_rate\"]),\n",
    "    warmup_ratio=args_dict[\"warm_up\"],\n",
    "    label_smoothing_factor=args_dict[\"label_smoothing\"],\n",
    "    per_device_train_batch_size=args_dict[\"batch_size\"],\n",
    "    per_device_eval_batch_size=args_dict[\"batch_size\"],\n",
    "    gradient_accumulation_steps=args_dict[\"gradient_accumulation_steps\"],\n",
    "    num_train_epochs=args_dict[\"epochs\"],\n",
    "    weight_decay=args_dict[\"weight_decay\"],\n",
    "    logging_strategy=args_dict[\"logging_strategy\"],\n",
    "    logging_steps=args_dict[\"logging_steps\"],\n",
    "    load_best_model_at_end=args_dict[\"load_best\"],\n",
    "    metric_for_best_model=args_dict[\"metric_used\"],\n",
    "    greater_is_better=args_dict[\"greater_better\"],\n",
    "    save_strategy=args_dict[\"save_strategy\"],\n",
    "    save_steps=args_dict[\"save_steps\"],\n",
    "    save_total_limit=args_dict[\"save_limits\"],\n",
    "    dataloader_num_workers=args_dict[\"workers\"],\n",
    "    disable_tqdm=False,\n",
    "    remove_unused_columns=True,\n",
    "    dataloader_drop_last=args_dict[\"load_best\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a61d34a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Train Model <a class=\"anchor\" id=\"Train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dbb6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = trainer_class(\n",
    "    model_obj.model,\n",
    "    training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"valid\"],\n",
    "    tokenizer=model_obj.tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator = data_collator\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=args_dict[\"resume_from_checkpoint\"])\n",
    "\n",
    "print(\"finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e2b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj.model.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c9f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_res = trainer.evaluate()\n",
    "print(eval_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162eee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to saving from here\n",
    "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
    "trainer.save_model(f\"models/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a89535",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, labels, metrics = trainer.predict(dataset[\"test\"])\n",
    "predictions = logits.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3769f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Log this properly\n",
    "log = classification_report(\n",
    "        labels,\n",
    "        predictions,\n",
    "        #np.unique(labels),\n",
    "        target_names=dataset[\"test\"].features[\"label\"].names,\n",
    "    )\n",
    "print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done... saving model\")\n",
    "\n",
    "trainer.save_model(f\"models/{filename}\")\n",
    "model_obj.model.save_pretrained(f\"pretrained/{filename}\")\n",
    "model_obj.tokenizer.save_pretrained(f\"pretrained/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f33f7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "with open(f\"pretrained/{filename}/classification_report.txt\", 'w', encoding='utf-8') as f:\n",
    "    f.write(log)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c1245b53e1ac3e3ad0b9c04975c6ada1b452cda2323d5254bedd444152d9115"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
